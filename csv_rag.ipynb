{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings \n",
    "from langchain_chroma import Chroma \n",
    "from langchain_community.chat_models import ChatOllama \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv loader and vector retriever\n",
    "loader_4g = CSVLoader(file_path=\"./documents/kpi_4g.csv\")\n",
    "data_4g = loader_4g.load() \n",
    "vector_store_4g = Chroma.from_documents(documents=data_4g , embedding=OllamaEmbeddings(model=\"llama3\") , collection_name=\"4gkpis\")\n",
    "\n",
    "loader_2g = CSVLoader(file_path=\"./documents/kpi_2g.csv\")\n",
    "data_2g = loader_2g.load() \n",
    "vector_store_2g = Chroma.from_documents(documents=data_2g , embedding=OllamaEmbeddings(model=\"llama3\") , collection_name=\"2gkpis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'row': 32, 'source': './documents/kpi_4g.csv'}, page_content='KPI Name: MAX_MAX_RRC_USER\\nKPI Formula: max(MAX_RRC_CONN_USER)'),\n",
       " Document(metadata={'row': 34, 'source': './documents/kpi_4g.csv'}, page_content='KPI Name: AVG_RRC_CONN_USER\\nKPI Formula: avg(AVG_RRC_CONN_USER)'),\n",
       " Document(metadata={'row': 30, 'source': './documents/kpi_4g.csv'}, page_content='KPI Name: AVG_MAX_RRC_USER\\nKPI Formula: avg(MAX_RRC_CONN_USER)'),\n",
       " Document(metadata={'row': 31, 'source': './documents/kpi_4g.csv'}, page_content='KPI Name: SUM_MAX_RRC_USER\\nKPI Formula: sum(MAX_RRC_CONN_USER)')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store_4g.similarity_search(\"DROP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The formula for 4G RRC Setup success rate is 100*sum(RRC_SETUP_NUM)/sum(RRC_SETUP_DENOM).\n",
      "The formula for 2G TCH Drop is not provided in the given context. The provided documents are related to 4G KPIs, and there is no mention of 2G or TCH (Traffic Channel).\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"llama3\")\n",
    "message = \"\"\"\n",
    "You are specialize agent in telecommunication field. Answer the question based on provided context and do not format the answer in multiple line. \n",
    "\n",
    "{question}\n",
    "\n",
    "Context: \n",
    "{context}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(message)\n",
    "parser = StrOutputParser()\n",
    "retriver = Chroma(persist_directory=\"./db4g\" , embedding_function=OllamaEmbeddings(model=\"llama3\")).as_retriever()\n",
    "\n",
    "chain = {\n",
    "    \"context\": retriver , \n",
    "    \"question\": RunnablePassthrough()\n",
    "} | prompt | llm | parser\n",
    "\n",
    "\n",
    "print(chain.invoke({\"question\": \"What is the formula for 4G RRC Setup success rate\"}))\n",
    "print(chain.invoke({\"question\": \"What is the formula for 2G TCH Drop?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'technology': '4G', 'question': 'What is the formula for LTE RRC Setup success rate'}\n",
      "I don't know. The provided context is related to 2G KPIs, but it doesn't mention LTE or RRC Setup success rate, so I'm not able to provide an answer for that specific question.\n",
      "{'technology': '2G', 'question': 'What is the formula for 2G TCH Drop?'}\n",
      "The formula for 2G TCH Drop is 100*sum(TCH_DROP_NUM)/sum(TCH_DROP_DENOM).\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.globals import set_debug , set_verbose\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "chain_technology = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are telecommunication field specialist agent. Given user question below, classify the question is related to which radio field topic, either '4G', '3G', '2G' or 'unclear'\n",
    "        Do not response other word\n",
    "        \n",
    "        User: {question}\n",
    "        Answer: \n",
    "        \"\"\"\n",
    "    ) | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "def route(info):\n",
    "    print(info)\n",
    "    retriever = Chroma(persist_directory=\"./db4g\" if \"4G\" in info else \"./db2g\" ,  embedding_function=OllamaEmbeddings(model=\"llama3\")).as_retriever(\n",
    "        \n",
    "    )\n",
    "    return {\n",
    "        \"context\": retriever  , \n",
    "        \"question\": RunnablePassthrough(),\n",
    "    } | (\n",
    "        ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are specialize agent in telecommunication field. Answer the question based on only provided context and do not format the answer in multiple line.\n",
    "        If provided context does not related to the question, just mention you don't know\n",
    "\n",
    "        {question}\n",
    "\n",
    "        Context: \n",
    "        {context}\n",
    "        \"\"\")\n",
    "    ) | llm | StrOutputParser()\n",
    "        \n",
    "full_chain = {\"technology\":chain_technology, \"question\": lambda x: x['question']} | RunnableLambda(route)\n",
    "print(full_chain.invoke({\"question\": \"What is the formula for LTE RRC Setup success rate\"}))\n",
    "print(full_chain.invoke({\"question\": \"What is the formula for 2G TCH Drop?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'row': 19, 'source': './documents/kpi_4g.csv'}, page_content='KPI Name: SRVCC_SETUP_SUCCESS_RATE\\nKPI Formula: 100*sum(SRVCC_NUM)/sum(SRVCC_DENOM)'),\n",
       " Document(metadata={'row': 27, 'source': './documents/kpi_4g.csv'}, page_content='KPI Name: DL_PDCP_SDU_LOSS_RATE\\nKPI Formula: 100*sum(DL_PDCP_LOSS_NUM)/sum(DL_PDCP_LOSS_DENOM)'),\n",
       " Document(metadata={'row': 28, 'source': './documents/kpi_4g.csv'}, page_content='KPI Name: UL_PDCP_SDU_LOSS_RATE\\nKPI Formula: 100*sum(UL_PDCP_LOSS_NUM)/sum(UL_PDCP_LOSS_DENOM)'),\n",
       " Document(metadata={'row': 1, 'source': './documents/kpi_4g.csv'}, page_content='KPI Name: RRC_SETUP_SUCCESS_RATE\\nKPI Formula: 100*sum(RRC_SETUP_NUM)/sum(RRC_SETUP_DENOM)')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chroma(persist_directory=\"./db4g\" ,  embedding_function=OllamaEmbeddings(model=\"llama3\")).search(\"What is the formula for 4G RRC Setup success rate\", search_type=\"similarity\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel , Field  \n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions # ChatOllama does not support schema json output\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "class QueryKPI(BaseModel): \n",
    "    \"\"\"Extract user question regarding KPI in telecommunication field.\"\"\"\n",
    "    \n",
    "    kpi_name : str = Field(description=\"KPI name for telecommunication field\")\n",
    "    technology: str = Field(description=\"Technology of radio communication\")\n",
    "\n",
    "model = OllamaFunctions(model=\"llama3\")\n",
    "# model = ChatOpenAI(\n",
    "#     model='gpt-3.5-turbo',\n",
    "#     api_key=\"API_KEY\",\n",
    "# )\n",
    "structure_model = model.with_structured_output(QueryKPI)\n",
    "\n",
    "structure_chain = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are telecommunication field specialist agent. Given user question below, classify the question is related to which radio field topic, output in '4G', '3G', '2G' or 'unclear' only. \n",
    "        You should also identify the kpi name related to telecommunication that user is asking and kpi name shall not contain any technology| word such as LTE, 4G, etc.\n",
    "        \n",
    "        User: {question}\n",
    "        \"\"\"\n",
    "    ) | structure_model \n",
    ")\n",
    "#print(structure_chain.invoke({\"question\": \"What is the formula for LTE RRC Setup success rate\"}).kpi_name)\n",
    "\n",
    "def _get_kpiname(input)->str: \n",
    "    return input['kpi_extraction'].kpi_name\n",
    "\n",
    "def route(info):\n",
    "    retriever = Chroma(persist_directory=\"./db4g\" if (\"4G\" in info['kpi_extraction'].technology or \"LTE\" in info['kpi_extraction'] ) else \"./db2g\" ,  embedding_function=OllamaEmbeddings(model=\"llama3\")).as_retriever(search_kwargs={\"k\":5})\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"context\": _get_kpiname | retriever , \n",
    "        \"question\": RunnablePassthrough(),\n",
    "    } | (\n",
    "        ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are specialize agent in telecommunication field. Answer the question based on only provided context and do not format the answer in multiple line.\n",
    "        If provided context does not related to the question, just mention you don't know\n",
    "\n",
    "        {question}\n",
    "\n",
    "        Context: \n",
    "        {context}\n",
    "        \n",
    "        Return the formula only with kpi name as follow: \n",
    "        KPI_NAME=KPI_FORMULA\n",
    "        \"\"\")\n",
    "    ) | llm | StrOutputParser()\n",
    "        \n",
    "full_chain = {\"kpi_extraction\": structure_chain , \"question\": lambda x: x['question']} | RunnableLambda(route)\n",
    "#print(full_chain.invoke({\"question\": \"What is the formula for LTE RRC Setup success rate\"}))\n",
    "#print(full_chain.invoke({\"question\": \"What is the formula for 2G TCH Drop?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KPI_NAME=TCH Drop, KPI_FORMULA=100*sum(TCH_DROP_NUM)/sum(TCH_DROP_DENOM)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"What is the formula for 2G TCH Drop\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RRC Setup Success Rate=100*sum(RRC_SETUP_NUM)/sum(RRC_SETUP_DENOM)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\":\"What is the formula for RRC Setup Success Rate?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO \n",
    "# 1. Try dynamic load vector ? \n",
    "# 2. Output schema \n",
    "# 3. CSV RAG Agent\n",
    "# 4. LangGraph\n",
    "# 5. non support LLM\n",
    "# 6. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
